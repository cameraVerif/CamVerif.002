/home/habeeb/anaconda3/envs/abc_iisc/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/habeeb/anaconda3/envs/abc_iisc/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
/home/habeeb/anaconda3/envs/abc_iisc/lib/python3.7/site-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.
  warnings.warn("Note that order of the arguments: ceil_mode and return_indices will change"
Configurations:

general:
  device: cpu
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  record_bounds: false
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: false
  csv_name: null
  results_file: abc_out_y2.txt
  root_path: ''
model:
  name: null
  path: null
  onnx_path: OGmodel_pb_converted.onnx
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
data:
  start: 0
  end: 10000
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  vnnlib_path: prop_y2.vnnlb
  vnnlib_path_prefix: ''
solver:
  batch_size: 64
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  multi_class:
    multi_class_method: allclass_domain
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: min
    sb_coeff_thresh: 0.001
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      sort_domain_interval: -1
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  cex_path: ./test_cex.txt
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  lp_test: null

Experiments at Sat Jan 11 12:07:52 2025 on habeeb-Lenovo-IdeaPad-S540-15IML-D
Internal results will be saved to abc_out_y2.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx OGmodel_pb_converted.onnx
Using vnnlib prop_y2.vnnlb
.compiled file md5: 1aa51f602fcac1abe65968609e5658ab does not match the current vnnlib md5: 27e031507bbc1456069969f08563ab85. Regenerating...
7203 inputs and 3 outputs in vnnlib
Loading onnx OGmodel_pb_converted.onnx wih quirks {}
model converted
ConvertModel(
  (Transpose_StatefulPartitionedCall/sequential/conv2d/BiasAdd__6:0): Transpose()
  (Conv_StatefulPartitionedCall/sequential/conv2d/BiasAdd:0): Conv2d(3, 32, kernel_size=(4, 4), stride=(1, 1))
  (Relu_StatefulPartitionedCall/sequential/conv2d/Relu:0): ReLU(inplace=True)
  (MaxPool_StatefulPartitionedCall/sequential/max_pooling2d/MaxPool:0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (Conv_StatefulPartitionedCall/sequential/conv2d_1/BiasAdd:0): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1))
  (Relu_StatefulPartitionedCall/sequential/conv2d_1/Relu:0): ReLU(inplace=True)
  (MaxPool_StatefulPartitionedCall/sequential/max_pooling2d_1/MaxPool:0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (Conv_StatefulPartitionedCall/sequential/conv2d_2/BiasAdd:0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
  (Relu_StatefulPartitionedCall/sequential/conv2d_2/Relu:0): ReLU(inplace=True)
  (MaxPool_StatefulPartitionedCall/sequential/max_pooling2d_2/MaxPool:0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  (Transpose_StatefulPartitionedCall/sequential/max_pooling2d_2/MaxPool__28:0): Transpose()
  (Reshape_StatefulPartitionedCall/sequential/flatten/Reshape:0): Reshape(shape=[ -1 512])
  (MatMul_StatefulPartitionedCall/sequential/dense/BiasAdd:0): Linear(in_features=512, out_features=200, bias=True)
  (Relu_StatefulPartitionedCall/sequential/dense/Relu:0): ReLU(inplace=True)
  (MatMul_dense_1): Linear(in_features=200, out_features=3, bias=True)
)
Attack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.07449999451637268, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[-7.25225115,  6.73018408, -0.08534458]])
pgd early stop
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-3.98040199,  1.73166609,  2.24226046]]])
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[-6.22266245, -0.51059437]]])
number of violation:  2
Attack finished in 0.1020 seconds.
PGD attack succeeded!
Result: sat
Time: 0.21388006210327148
